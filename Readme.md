This repository contains the spectrogram images of the audio files from four different emotional speech datasets - CREMA-D, RAVDESS, TESS, and SAVEE. Each dataset has a unique set of characteristics that make them useful for training emotion classifiers.

The Crowd Sourced Emotional Multimodal Actors Dataset (CREMA-D) is a dataset of 7,442 original clips from 91 actors of different ages, genders, and ethnicities. Actors spoke from a selection of 12 sentences presented with six different emotions and four different emotion levels. This variety of data helps train a model that can be generalized across new datasets, making CREMA-D an excellent dataset to ensure that the model does not overfit.

The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) contains 1440 speech audio-only files from 24 professional actors (12 female, 12 male) vocalizing two lexically-matched statements in a neutral North American accent. Speech emotions include calm, happy, sad, angry, fearful, surprise, and disgust expressions. Each expression is produced at two levels of emotional intensity, with an additional neutral expression. This dataset's unique feature is its use of North American accents, making it useful for emotion classification in North American English speech.

The Toronto emotional speech set (TESS) contains 2800 audio files from two actresses, each vocalizing sentences in seven emotional categories: anger, disgust, fear, happiness, pleasant surprise, sadness, and neutral. This dataset's uniqueness is that the same actress vocalizes all sentences in a given emotion, making it useful for studying the impact of individual differences in speech.

The Surrey Audio-Visual Expressed Emotion (SAVEE) dataset was recorded from four native English male speakers, postgraduate students, and researchers at the University of Surrey, vocalizing different emotions - anger, disgust, fear, happiness, sadness, and surprise - in a neutral tone of voice. This dataset's unique feature is that it uses only male speakers, making it useful for training emotion classifiers that can generalize to male speakers' voices. However, due to the lack of female speakers, it is recommended to complement this dataset with datasets containing more female speakers.

Thanks to Everyone who created the audio files by which i was able to create the spectrogram images.